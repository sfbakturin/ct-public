# Text

В качестве выбранного признака - категория подданного текста краткого содержания случайного из некоторого подмножества предсказуемых категорий. При этом, важно понимать, что статья обязаны быть статьёй, а не технической странице или страницей поиска (как это часто бывает "Here list of ..."). Также под *категорией* следует понимать абстрактный и вбирающий в себя множество менее связных с друг другом категорий. Например: биология, игры или культура.

**Выбранная NLP-задача**: *классификация*.

## Условие

1. Получите доступ к API любой LLM.

    Если у вас нет аккаунта OpenAI, то время его завести или найти качественный сервис-посредник. Программный доступ к LLM полезен во многих ситуациях.

2. Соберите датасет из текстов.

    Берите имеющийся или парсите новый. Можно использовать API.

3. Разметьте данные.

    Используйте LLM из пункта 1. Напишите подробный промпт с описанием задачи. Разметьте весь датасет или такую его часть, которой достаточно для того, чтобы хорошо предсказывать целевую переменную.

4. Реализуйте текстовую модель.

    Это может быть простая DL модель: `nn.Embedding` + `nn.LSTM` + `nn.Linear` (разобрано на лекции), сложная предобученная модель, в которой вы честно разобрались или скучная модель из классического обучения (кроме `tf-idf` и `naive bayes`, которые уже разобрали на лекции). Использовать реализацию `Word2Vec` из `gensim` как свою модель нельзя

5. Обучите модель на размеченном датасете.

    Измерьте качество модели.

      * Посчитайте метрики на *train* и *test*.
      * (опционально, но интересно) создайте *эмбеддинги* текстов: используйте выход предпоследнего *Linear* слоя. Следующий слой модели предсказывает по этому *эмбеддингу* ответ, поэтому в эмбеддинге на этом слое собрана вся полезная информация. Используйте метод снижения размерности, чтобы отобразить текст на 2D плоскости. Цветом укажите целевую переменную.
      * (опционально, но полезно) используйте `tensorboard` для логирования метрик во время обучения модели.

## Структура проекта

* [**`Text.ipynb`**](Text.ipynb) — решение и отчет по проделанной работе.
* [**`crawler.py`**](crawler.py) — сборщик статей по категориям Википедии.
* [**`config.py`**](config.py) — все установленные константы в отдельном файле, в том числе и список интересуемых статей.
* [**`requirements.txt`**](requirements.txt) — необходимые библиотеки для запуска основного решения.
